{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":421199,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":343271,"modelId":364552}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import onnx\nimport numpy as np\nimport pandas as pd\nfrom onnx import numpy_helper\nimport os\n\n# Load the ONNX model\nmodel_path = \"/kaggle/input/vggweightstointarsh/tensorflow2/default/1/vgg16-7.onnx\"\nonnx_model = onnx.load(model_path)\n\n# Output CSV path\noutput_csv = \"/kaggle/working/VGG_Float_Layerwise.csv\"\n\n# Remove file if it already exists\nif os.path.exists(output_csv):\n    os.remove(output_csv)\n\n# Flag to know if it's the first column (to write header)\nfirst_column = True\n\n# Stream weights layer by layer\nfor initializer in onnx_model.graph.initializer:\n    layer_name = initializer.name\n\n    # Skip non-weight data if needed (optional)\n    if not (\".weight\" in layer_name or \"conv\" in layer_name or \"fc\" in layer_name):\n        continue\n\n    # Flatten and reshape to a column vector\n    weights = numpy_helper.to_array(initializer).flatten()\n    df_col = pd.DataFrame({layer_name: weights})\n\n    # Append column to CSV\n    if first_column:\n        df_col.to_csv(output_csv, index=False)\n        first_column = False\n    else:\n        # Read existing CSV and merge column-wise\n        existing_df = pd.read_csv(output_csv)\n        merged_df = pd.concat([existing_df, df_col], axis=1)\n        merged_df.to_csv(output_csv, index=False)\n\n    print(f\"✅ Processed: {layer_name} with {len(weights)} weights\")\n\nprint(\"\\n✅ All layers written to:\", output_csv)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:11:44.947597Z","iopub.execute_input":"2025-06-01T17:11:44.947928Z","iopub.status.idle":"2025-06-01T17:20:56.666809Z","shell.execute_reply.started":"2025-06-01T17:11:44.947904Z","shell.execute_reply":"2025-06-01T17:20:56.665794Z"}},"outputs":[{"name":"stdout","text":"✅ Processed: vgg0_conv0_weight with 1728 weights\n✅ Processed: vgg0_conv0_bias with 64 weights\n✅ Processed: vgg0_conv1_weight with 36864 weights\n✅ Processed: vgg0_conv1_bias with 64 weights\n✅ Processed: vgg0_conv2_weight with 73728 weights\n✅ Processed: vgg0_conv2_bias with 128 weights\n✅ Processed: vgg0_conv3_weight with 147456 weights\n✅ Processed: vgg0_conv3_bias with 128 weights\n✅ Processed: vgg0_conv4_weight with 294912 weights\n✅ Processed: vgg0_conv4_bias with 256 weights\n✅ Processed: vgg0_conv5_weight with 589824 weights\n✅ Processed: vgg0_conv5_bias with 256 weights\n✅ Processed: vgg0_conv6_weight with 589824 weights\n✅ Processed: vgg0_conv6_bias with 256 weights\n✅ Processed: vgg0_conv7_weight with 1179648 weights\n✅ Processed: vgg0_conv7_bias with 512 weights\n✅ Processed: vgg0_conv8_weight with 2359296 weights\n✅ Processed: vgg0_conv8_bias with 512 weights\n✅ Processed: vgg0_conv9_weight with 2359296 weights\n✅ Processed: vgg0_conv9_bias with 512 weights\n✅ Processed: vgg0_conv10_weight with 2359296 weights\n✅ Processed: vgg0_conv10_bias with 512 weights\n✅ Processed: vgg0_conv11_weight with 2359296 weights\n✅ Processed: vgg0_conv11_bias with 512 weights\n✅ Processed: vgg0_conv12_weight with 2359296 weights\n✅ Processed: vgg0_conv12_bias with 512 weights\n\n✅ All layers written to: /kaggle/working/VGG_Float_Layerwise.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load the CSV file (adjust path as needed)\ncsv_path = '/kaggle/working/VGG_Float_Layerwise.csv'\ndf = pd.read_csv(csv_path)\n\n# Check for any non-numeric or NaN values\ndf = df.apply(pd.to_numeric, errors='coerce')  # Coerce non-numeric values to NaN\ndf = df.fillna(0)  # Replace NaNs with 0 (or use another strategy if needed)\n\n# Get global min and max\nmin_val = df.min().min()\nmax_val = df.max().max()\n\n# Handle case where min == max to avoid division by zero\nif min_val == max_val:\n    scale = 1\nelse:\n    scale = 255 / (max_val - min_val)\n# Vectorized conversion function\ndef float_to_int8_vectorized(x):\n    return np.round((x - min_val) * scale - 128).astype(np.int8)\n\n# Apply the function using vectorized approach\ndf_int8 = df.apply(float_to_int8_vectorized)\n\n# Save the result\noutput_path = '/kaggle/working/VGG_Int8_Weights.csv'\ndf_int8.to_csv(output_path, index=False)\n\nprint(f\"✅ Conversion completed and saved to {output_path}\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:27:43.529491Z","iopub.execute_input":"2025-06-01T17:27:43.529862Z","iopub.status.idle":"2025-06-01T17:28:09.563700Z","shell.execute_reply.started":"2025-06-01T17:27:43.529830Z","shell.execute_reply":"2025-06-01T17:28:09.562716Z"}},"outputs":[{"name":"stdout","text":"✅ Conversion completed and saved to /kaggle/working/VGG_Int8_Weights.csv\n","output_type":"stream"}],"execution_count":4}]}