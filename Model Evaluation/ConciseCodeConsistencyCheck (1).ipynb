{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001cf474-c433-4bba-a352-8c5b8f5aa720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and quantizing VGG16 model...\n",
      "Using device: cuda\n",
      "Quantization complete.\n",
      "Preparing test data...\n",
      "Directory 'test_data' already exists. Skipping extraction.\n",
      "Test data loaded successfully.\n",
      "Starting consistency and accuracy check...\n",
      "\n",
      "--- Final Results ---\n",
      "Top-1 Prediction Consistency: 95.24%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Helper Functions and Quantizer Class ---\n",
    "# A module to perform absmax quantization and dequantization\n",
    "class AbsMaxQuantizer(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        \n",
    "        # Get weights and quantize them on initialization\n",
    "        weights = layer.weight.data\n",
    "        max_val = torch.max(torch.abs(weights))\n",
    "        self.scale = 127.0 / max_val\n",
    "        self.quantized_weights = torch.round(weights * self.scale).to(torch.int8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # De-quantize the weights for computation\n",
    "        dequantized_weights = self.quantized_weights.to(torch.float32) / self.scale\n",
    "        \n",
    "        # Perform the original layer's forward pass with the de-quantized weights\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            return nn.functional.conv2d(x, dequantized_weights, self.layer.bias, self.layer.stride, self.layer.padding)\n",
    "        elif isinstance(self.layer, nn.Linear):\n",
    "            return nn.functional.linear(x, dequantized_weights, self.layer.bias)\n",
    "        else:\n",
    "            return self.layer(x)\n",
    "\n",
    "# --- 2. Model Loading and Quantization ---\n",
    "print(\"Loading and quantizing VGG16 model...\")\n",
    "model_original = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "model_quantized = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model_original.to(device)\n",
    "model_quantized.to(device)\n",
    "\n",
    "for name, module in model_quantized.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "        path = name.split('.')\n",
    "        parent = model_quantized\n",
    "        for i in range(len(path) - 1):\n",
    "            parent = parent._modules[path[i]]\n",
    "        layer_name = path[-1]\n",
    "        quantized_layer = AbsMaxQuantizer(module)\n",
    "        setattr(parent, layer_name, quantized_layer)\n",
    "print(\"Quantization complete.\")\n",
    "\n",
    "# --- 3. Data Extraction and Loading ---\n",
    "print(\"Preparing test data...\")\n",
    "zip_file_path = \"testABC.zip\"\n",
    "extracted_folder_name = \"test_data\"\n",
    "\n",
    "if not os.path.exists(extracted_folder_name):\n",
    "    print(f\"Extracting {zip_file_path}...\")\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder_name)\n",
    "else:\n",
    "    print(f\"Directory '{extracted_folder_name}' already exists. Skipping extraction.\")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=extracted_folder_name, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "print(\"Test data loaded successfully.\")\n",
    "\n",
    "# --- 4. Consistency and Accuracy Calculation ---\n",
    "print(\"Starting consistency and accuracy check...\")\n",
    "model_original.eval()\n",
    "model_quantized.eval()\n",
    "\n",
    "consistency_matches = 0\n",
    "original_correct = 0\n",
    "quantized_correct = 0\n",
    "total_images = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output_original = model_original(images)\n",
    "        _, preds_original = torch.max(output_original, 1)\n",
    "\n",
    "        output_quantized = model_quantized(images)\n",
    "        _, preds_quantized = torch.max(output_quantized, 1)\n",
    "\n",
    "        consistency_matches += (preds_original == preds_quantized).sum().item()\n",
    "        original_correct += (preds_original == labels).sum().item()\n",
    "        quantized_correct += (preds_quantized == labels).sum().item()\n",
    "\n",
    "        total_images += images.size(0)\n",
    "\n",
    "consistency_percentage = (consistency_matches / total_images) * 100\n",
    "original_accuracy = (original_correct / total_images) * 100\n",
    "quantized_accuracy = (quantized_correct / total_images) * 100\n",
    "\n",
    "print(\"\\n--- Final Results ---\")\n",
    "print(f\"Top-1 Prediction Consistency: {consistency_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3da03-9bbb-4ac2-b89e-f5ffe00cc2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
