{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12083145,"sourceType":"datasetVersion","datasetId":7606515},{"sourceId":12083176,"sourceType":"datasetVersion","datasetId":7606535},{"sourceId":12083198,"sourceType":"datasetVersion","datasetId":7606551}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport os\nimport pandas as pd # Added pandas for robust CSV loading\n\n# --- Configuration ---\n# Input image path (ensure this file exists in your Kaggle input or working directory)\nINPUT_IMAGE_PATH = '/kaggle/input/samplephoto1/pexels-pixabay-220938.jpg'\n# Output path for the hex representation of the image\nOUTPUT_HEX_FILE_PATH = 'image_pixels_hex.hex' # Updated extension to .hex as per your log\n# Path to the file containing integer weights (e.g., a 3x3 filter)\nINTEGER_WEIGHTS_FILE_PATH = '/kaggle/input/arshus/VGG_Int8_Weights (4).csv'\n# Output path for the convolved result (content will be text, not an actual image file)\nCONVOLVED_OUTPUT_FILE_PATH = 'convolved_output_from_hex.txt' # Keeping as .txt as content is text\n\n# Desired size for the image (resizing for consistent processing)\nTARGET_IMAGE_SIZE = (50, 50) # Width, Height\n\n# --- Helper Functions ---\n\ndef create_dummy_image(path, size=(50, 50)):\n    \"\"\"Creates a dummy grayscale image if one doesn't exist.\"\"\"\n    if not os.path.exists(path):\n        print(f\"Creating dummy image at {path}...\")\n        img = Image.new('L', size, color = 'grey') # 'L' for grayscale\n        img.save(path)\n        print(\"Dummy image created.\")\n\ndef create_dummy_weights_file(path, weights_shape=(3, 3)):\n    \"\"\"Creates a dummy integer weights file (e.g., a 3x3 filter).\"\"\"\n    if not os.path.exists(path):\n        print(f\"Creating dummy integer weights file at {path}...\")\n        # Example: a simple edge detection filter\n        dummy_weights = np.array([\n            [1, 0, -1],\n            [2, 0, -2],\n            [1, 0, -1]\n        ], dtype=int)\n        # Ensure the dummy weights match the desired shape\n        if dummy_weights.shape != weights_shape:\n            # If shape doesn't match, create random integers for the specified shape\n            dummy_weights = np.random.randint(-5, 5, size=weights_shape)\n\n        # Use np.savetxt for dummy file, assuming simple numerical format\n        np.savetxt(path, dummy_weights, fmt='%d')\n        print(\"Dummy weights file created.\")\n\ndef image_to_hex_file(image_path, output_hex_path, target_size):\n    \"\"\"\n    Converts an image to grayscale, resizes it, and saves its pixel values\n    as a hex string in a file, formatted with line numbers.\n    \"\"\"\n    print(f\"\\n--- Converting image '{image_path}' to hex format ---\")\n    try:\n        # Open image and convert to grayscale ('L' mode)\n        img = Image.open(image_path).convert('L')\n        # Resize image to target size\n        img = img.resize(target_size)\n        # Get pixel data as a NumPy array\n        pixel_array = np.array(img)\n\n        with open(output_hex_path, 'w') as f:\n            line_num = 1\n            # Iterate through each pixel\n            for pixel_value in pixel_array.flatten():\n                # Convert pixel value (0-255) to 2-digit hexadecimal string\n                hex_value = f\"{pixel_value:02X}\"\n                # Write in the format: line_number hex_value\n                f.write(f\"{line_num}\\t{hex_value}\\n\")\n                line_num += 1\n        print(f\"Image successfully converted to hex and saved to '{output_hex_path}'.\")\n        return pixel_array # Return the pixel array for later use\n    except FileNotFoundError:\n        print(f\"Error: Image file not found at '{image_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"An error occurred during image to hex conversion: {e}\")\n        return None\n\ndef load_integer_weights(weights_file_path):\n    \"\"\"\n    Loads integer weights from a text file (CSV) into a NumPy array.\n    This version specifically tries to extract a 3x3 kernel from the *start*\n    of the flattened weights, assuming the CSV contains flattened weights.\n    \"\"\"\n    print(f\"\\n--- Loading integer weights from '{weights_file_path}' ---\")\n    try:\n        # Read the CSV, assuming it might have a header.\n        # We'll read all columns as strings initially to avoid conversion errors on header.\n        df = pd.read_csv(weights_file_path, header=None, dtype=str)\n\n        # Find the first row that contains numerical data.\n        # Iterate through rows and try to convert the first element to float.\n        data_start_row = 0\n        for i in range(len(df)):\n            try:\n                # Try converting the first element of the row to float.\n                # This assumes the actual numerical data starts in the first column.\n                _ = float(df.iloc[i, 0])\n                data_start_row = i\n                break\n            except ValueError:\n                continue\n        \n        if data_start_row > 0:\n            print(f\"Skipping {data_start_row} header row(s).\")\n\n        # Extract numerical data from the identified start row onwards, from the first column\n        # Convert to a 1D numpy array of integers\n        # Filter out any empty strings that might result from uneven rows or parsing\n        all_weights_str = df.iloc[data_start_row:, 0].values.flatten()\n        all_weights = [int(w) for w in all_weights_str if w.strip() != '']\n        \n        # VGG16 first conv layer kernel (3x3x3x64) has 1728 weights.\n        # For manual convolution, we need a single 3x3 kernel.\n        # We'll extract the first 9 weights and reshape them into a 3x3 kernel.\n        # This assumes these correspond to a 3x3 filter for one input/output channel.\n        if len(all_weights) < 9:\n            raise ValueError(f\"Not enough weights ({len(all_weights)}) found in the file to form a 3x3 kernel. Expected at least 9 numerical values.\")\n\n        # Extract the first 9 weights and reshape to 3x3\n        kernel = np.array(all_weights[:9]).reshape((3, 3))\n        \n        print(f\"Extracted 3x3 kernel from the beginning of the weights file.\")\n        print(f\"Kernel shape: {kernel.shape}\")\n        return kernel\n    except FileNotFoundError:\n        print(f\"Error: Weights file not found at '{weights_file_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"An error occurred during weights loading: {e}\")\n        # Provide more context if the error is a conversion issue\n        if 'could not convert string' in str(e) and 'df' in locals():\n            print(f\"Problematic data might be around row {data_start_row}, column 0. First few values: {df.iloc[data_start_row:, 0].head().to_list()}\")\n        return None\n\ndef perform_manual_convolution(image_pixels, kernel, output_file_path):\n    \"\"\"\n    Performs a manual 2D convolution operation (like a single CNN layer).\n    Uses 'valid' padding (no padding, filter only operates where it fully fits).\n    \"\"\"\n    print(f\"\\n--- Performing manual 2D convolution ---\")\n    if image_pixels is None or kernel is None:\n        print(\"Cannot perform convolution: image pixels or kernel are missing.\")\n        return\n\n    image_height, image_width = image_pixels.shape\n    kernel_height, kernel_width = kernel.shape\n\n    # Calculate output dimensions for 'valid' padding\n    if image_height < kernel_height or image_width < kernel_width:\n        print(\"Error: Image dimensions are smaller than kernel dimensions. Cannot convolve.\")\n        return\n\n    output_height = image_height - kernel_height + 1\n    output_width = image_width - kernel_width + 1\n\n    # Initialize the output feature map\n    output_feature_map = np.zeros((output_height, output_width), dtype=np.float32)\n\n    print(f\"Input Image Shape: {image_pixels.shape}\")\n    print(f\"Kernel Shape: {kernel.shape}\")\n    print(f\"Output Feature Map Shape: {output_feature_map.shape}\")\n\n    # Iterate over the output feature map dimensions\n    for i in range(output_height):\n        for j in range(output_width):\n            # Extract the image patch\n            image_patch = image_pixels[i : i + kernel_height,\n                                       j : j + kernel_width]\n\n            # Element-wise multiplication and summation\n            convolved_value = np.sum(image_patch * kernel)\n            output_feature_map[i, j] = convolved_value\n\n    print(\"Manual convolution complete.\")\n\n    # Save the convolved output to a file\n    try:\n        with open(output_file_path, 'w') as f:\n            f.write(f\"Manual 2D Convolution Output (from hex-converted image)\\n\")\n            f.write(f\"Input Image Dimensions: {image_height}x{image_width}\\n\")\n            f.write(f\"Kernel Used:\\n{kernel}\\n\")\n            f.write(f\"Output Feature Map Dimensions: {output_height}x{output_width}\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            f.write(np.array_str(output_feature_map, precision=4, suppress_small=True))\n            f.write(\"\\n\")\n        print(f\"Convolved output saved to '{output_file_path}'.\")\n    except Exception as e:\n        print(f\"Error saving convolved output to file: {e}\")\n\n# --- Main Execution ---\nif __name__ == \"__main__\":\n    # 1. Ensure dummy files exist for demonstration if not provided by user\n    # These dummy files are created only if the specified paths don't exist.\n    # In a Kaggle notebook, you'd typically use paths from /kaggle/input/\n    create_dummy_image(INPUT_IMAGE_PATH, TARGET_IMAGE_SIZE)\n    create_dummy_weights_file(INTEGER_WEIGHTS_FILE_PATH)\n\n    # 2. Convert image to hex file format\n    # This function also returns the pixel array for direct use in convolution\n    image_pixels_array = image_to_hex_file(INPUT_IMAGE_PATH, OUTPUT_HEX_FILE_PATH, TARGET_IMAGE_SIZE)\n\n    # 3. Load integer weights\n    integer_weights_kernel = load_integer_weights(INTEGER_WEIGHTS_FILE_PATH)\n\n    # 4. Perform manual convolution (simulating one layer)\n    perform_manual_convolution(image_pixels_array, integer_weights_kernel, CONVOLVED_OUTPUT_FILE_PATH)\n\n    print(\"\\n--- Process Complete ---\")\n    print(f\"Check '{OUTPUT_HEX_FILE_PATH}' for hex representation of the image.\")\n    print(f\"Check '{CONVOLVED_OUTPUT_FILE_PATH}' for the result of the convolution (text content).\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-06T19:35:02.344962Z","iopub.execute_input":"2025-06-06T19:35:02.345279Z","iopub.status.idle":"2025-06-06T19:35:16.665599Z","shell.execute_reply.started":"2025-06-06T19:35:02.345256Z","shell.execute_reply":"2025-06-06T19:35:16.664848Z"}},"outputs":[{"name":"stdout","text":"\n--- Converting image '/kaggle/input/samplephoto1/pexels-pixabay-220938.jpg' to hex format ---\nImage successfully converted to hex and saved to 'image_pixels_hex.hex'.\n\n--- Loading integer weights from '/kaggle/input/arshus/VGG_Int8_Weights (4).csv' ---\nSkipping 1 header row(s).\nExtracted 3x3 kernel from the beginning of the weights file.\nKernel shape: (3, 3)\n\n--- Performing manual 2D convolution ---\nInput Image Shape: (50, 50)\nKernel Shape: (3, 3)\nOutput Feature Map Shape: (48, 48)\nManual convolution complete.\nConvolved output saved to 'convolved_output_from_hex.txt'.\n\n--- Process Complete ---\nCheck 'image_pixels_hex.hex' for hex representation of the image.\nCheck 'convolved_output_from_hex.txt' for the result of the convolution (text content).\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os  # Add this line to fix the image saving error\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef save_feature_map_as_image(feature_map, layer_idx, output_dir=\"outputs\"):\n    \"\"\"\n    Saves the feature map as a grayscale image.\n    \"\"\"\n    try:\n        normalized = feature_map - feature_map.min()\n        if normalized.max() > 0:\n            normalized = (normalized / normalized.max()) * 255\n        else:\n            normalized = np.zeros_like(feature_map)\n        img = Image.fromarray(normalized.astype(np.uint8))\n        os.makedirs(output_dir, exist_ok=True)\n        image_path = os.path.join(output_dir, f\"layer_{layer_idx}_output.png\")\n        img.save(image_path)\n        print(f\"✅ Layer {layer_idx} output image saved to: {image_path}\")\n    except Exception as e:\n        print(f\"Error saving image for Layer {layer_idx}: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T19:36:04.160198Z","iopub.execute_input":"2025-06-06T19:36:04.160747Z","iopub.status.idle":"2025-06-06T19:36:04.167047Z","shell.execute_reply.started":"2025-06-06T19:36:04.160722Z","shell.execute_reply":"2025-06-06T19:36:04.166284Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport os\n\ndef perform_manual_convolution(image_pixels, kernel):\n    if image_pixels is None or kernel is None:\n        return None\n    image_height, image_width = image_pixels.shape\n    kernel_height, kernel_width = kernel.shape\n    output_height = image_height - kernel_height + 1\n    output_width = image_width - kernel_width + 1\n    if output_height <= 0 or output_width <= 0:\n        print(\"Error: Kernel too large for the current input size.\")\n        return None\n    output_feature_map = np.zeros((output_height, output_width), dtype=np.float32)\n    for i in range(output_height):\n        for j in range(output_width):\n            patch = image_pixels[i:i+kernel_height, j:j+kernel_width]\n            output_feature_map[i, j] = np.sum(patch * kernel)\n    return output_feature_map\n\ndef save_feature_map_as_image(feature_map, layer_idx, output_dir=\"outputs\"):\n    try:\n        normalized = feature_map - feature_map.min()\n        if normalized.max() > 0:\n            normalized = (normalized / normalized.max()) * 255\n        else:\n            normalized = np.zeros_like(feature_map)\n        img = Image.fromarray(normalized.astype(np.uint8))\n        os.makedirs(output_dir, exist_ok=True)\n        image_path = os.path.join(output_dir, f\"layer_{layer_idx}_output.png\")\n        img.save(image_path)\n        print(f\"✅ Layer {layer_idx} output image saved to: {image_path}\")\n    except Exception as e:\n        print(f\"Error saving image for Layer {layer_idx}: {e}\")\n\n# Example simulated input image (replace with actual grayscale image array)\ninitial_input = np.random.randint(0, 256, size=(50, 50))\n\n# Example 3x3 kernels for 5 layers\nkernels = [\n    np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]]),\n    np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),\n    np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]]),\n    np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n    np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n]\n\n# Perform convolution through all layers\noutput = initial_input\nfor idx, kernel in enumerate(kernels, 1):\n    output = perform_manual_convolution(output, kernel)\n    if output is None:\n        print(f\"Stopping at Layer {idx} due to size mismatch.\")\n        break\n    print(f\"Layer {idx} output shape: {output.shape}\")\n    save_feature_map_as_image(output, idx)\n\nprint(\"✅ All convolution layers completed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T19:39:19.488450Z","iopub.execute_input":"2025-06-06T19:39:19.488771Z","iopub.status.idle":"2025-06-06T19:39:19.584965Z","shell.execute_reply.started":"2025-06-06T19:39:19.488748Z","shell.execute_reply":"2025-06-06T19:39:19.583840Z"}},"outputs":[{"name":"stdout","text":"Layer 1 output shape: (48, 48)\n✅ Layer 1 output image saved to: outputs/layer_1_output.png\nLayer 2 output shape: (46, 46)\n✅ Layer 2 output image saved to: outputs/layer_2_output.png\nLayer 3 output shape: (44, 44)\n✅ Layer 3 output image saved to: outputs/layer_3_output.png\nLayer 4 output shape: (42, 42)\n✅ Layer 4 output image saved to: outputs/layer_4_output.png\nLayer 5 output shape: (40, 40)\n✅ Layer 5 output image saved to: outputs/layer_5_output.png\n✅ All convolution layers completed.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Manual 2D convolution function\ndef perform_manual_convolution(image_pixels, kernel):\n    if image_pixels is None or kernel is None:\n        return None\n    image_height, image_width = image_pixels.shape\n    kernel_height, kernel_width = kernel.shape\n    output_height = image_height - kernel_height + 1\n    output_width = image_width - kernel_width + 1\n    if output_height <= 0 or output_width <= 0:\n        print(\"Error: Kernel too large for the input.\")\n        return None\n    output_feature_map = np.zeros((output_height, output_width), dtype=np.float32)\n    for i in range(output_height):\n        for j in range(output_width):\n            patch = image_pixels[i:i+kernel_height, j:j+kernel_width]\n            output_feature_map[i, j] = np.sum(patch * kernel)\n    return output_feature_map\n\n# Normalize feature map for display\ndef normalize_for_display(feature_map):\n    normalized = feature_map - feature_map.min()\n    if normalized.max() > 0:\n        normalized = (normalized / normalized.max()) * 255\n    else:\n        normalized = np.zeros_like(feature_map)\n    return normalized.astype(np.uint8)\n\n# Simulated input image (grayscale 50x50)\ninitial_input = np.random.randint(0, 256, size=(50, 50))\n\n# Define kernels for 5 layers (you can replace with real ones)\nkernels = [\n    np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]]),\n    np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),\n    np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]]),\n    np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n    np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n]\n\n# Run convolution and show each layer\noutput = initial_input\nfor idx, kernel in enumerate(kernels, 1):\n    output = perform_manual_convolution\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T19:41:36.293325Z","iopub.execute_input":"2025-06-06T19:41:36.293639Z","iopub.status.idle":"2025-06-06T19:41:36.304631Z","shell.execute_reply.started":"2025-06-06T19:41:36.293614Z","shell.execute_reply":"2025-06-06T19:41:36.303673Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport os\n\n# Manual 2D convolution\ndef perform_manual_convolution(image_pixels, kernel):\n    image_height, image_width = image_pixels.shape\n    kernel_height, kernel_width = kernel.shape\n    output_height = image_height - kernel_height + 1\n    output_width = image_width - kernel_width + 1\n    output_feature_map = np.zeros((output_height, output_width), dtype=np.float32)\n    for i in range(output_height):\n        for j in range(output_width):\n            patch = image_pixels[i:i+kernel_height, j:j+kernel_width]\n            output_feature_map[i, j] = np.sum(patch * kernel)\n    return output_feature_map\n\n# Save output as text matrix\ndef save_matrix_to_text_file(matrix, layer_idx, output_dir=\"matrix_outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    path = os.path.join(output_dir, f\"layer_{layer_idx}_matrix.txt\")\n    with open(path, 'w') as f:\n        f.write(f\"--- Convolution Output: Layer {layer_idx} ---\\n\")\n        f.write(np.array_str(matrix, precision=4, suppress_small=True))\n    print(f\"✅ Layer {layer_idx} matrix saved to {path}\")\n\n# Example input image (50x50)\ninitial_input = np.random.randint(0, 256, size=(50, 50))\n\n# Example 3x3 kernels for 5 layers\nkernels = [\n    np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]]),\n    np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),\n    np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]]),\n    np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n    np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n]\n\n# Perform convolution and save each output\noutput = initial_input\nfor idx, kernel in enumerate(kernels, 1):\n    output = perform_manual_convolution(output, kernel)\n    save_matrix_to_text_file(output, idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T19:45:50.185976Z","iopub.execute_input":"2025-06-06T19:45:50.186289Z","iopub.status.idle":"2025-06-06T19:45:50.279797Z","shell.execute_reply.started":"2025-06-06T19:45:50.186268Z","shell.execute_reply":"2025-06-06T19:45:50.278875Z"}},"outputs":[{"name":"stdout","text":"✅ Layer 1 matrix saved to matrix_outputs/layer_1_matrix.txt\n✅ Layer 2 matrix saved to matrix_outputs/layer_2_matrix.txt\n✅ Layer 3 matrix saved to matrix_outputs/layer_3_matrix.txt\n✅ Layer 4 matrix saved to matrix_outputs/layer_4_matrix.txt\n✅ Layer 5 matrix saved to matrix_outputs/layer_5_matrix.txt\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport os\n\n# 1. Manual 2D convolution\ndef perform_manual_convolution(image_pixels, kernel):\n    image_height, image_width = image_pixels.shape\n    kernel_height, kernel_width = kernel.shape\n    output_height = image_height - kernel_height + 1\n    output_width = image_width - kernel_width + 1\n    output_feature_map = np.zeros((output_height, output_width), dtype=np.float32)\n    for i in range(output_height):\n        for j in range(output_width):\n            patch = image_pixels[i:i+kernel_height, j:j+kernel_width]\n            output_feature_map[i, j] = np.sum(patch * kernel)\n    return output_feature_map\n\n# 2. Save output to text\ndef save_matrix_to_text_file(matrix, layer_idx, output_dir=\"vgg13_layer_outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    path = os.path.join(output_dir, f\"layer_{layer_idx}_matrix.txt\")\n    with open(path, 'w') as f:\n        f.write(f\"--- Convolution Output: Layer {layer_idx} ---\\n\")\n        f.write(np.array_str(matrix, precision=4, suppress_small=True))\n    print(f\"✅ Saved: {path}\")\n\n# 3. Simulated input image (50x50 grayscale)\ninitial_input = np.random.randint(0, 256, size=(50, 50))\n\n# 4. Simulated 3x3 kernels for 13 layers (you can replace with real ones later)\nkernels = [np.random.randint(-2, 3, size=(3, 3)) for _ in range(13)]\n\n# 5. Run all 13 conv layers\noutput = initial_input\nfor idx, kernel in enumerate(kernels, 1):\n    output = perform_manual_convolution(output, kernel)\n    if output is None or output.size == 0:\n        print(f\"❌ Stopped at Layer {idx} (invalid size).\")\n        break\n    save_matrix_to_text_file(output, idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-06T19:49:35.858869Z","iopub.execute_input":"2025-06-06T19:49:35.859126Z","iopub.status.idle":"2025-06-06T19:49:36.034320Z","shell.execute_reply.started":"2025-06-06T19:49:35.859106Z","shell.execute_reply":"2025-06-06T19:49:36.033357Z"}},"outputs":[{"name":"stdout","text":"✅ Saved: vgg13_layer_outputs/layer_1_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_2_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_3_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_4_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_5_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_6_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_7_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_8_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_9_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_10_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_11_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_12_matrix.txt\n✅ Saved: vgg13_layer_outputs/layer_13_matrix.txt\n","output_type":"stream"}],"execution_count":11}]}