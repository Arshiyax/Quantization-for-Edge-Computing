{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00edae6-8360-4004-9f5f-7189107f9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onnx in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.18.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (4.25.3)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnx numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ee25fa-2d91-44dd-9e9e-617894718b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onnx in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.18.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (4.25.3)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4225be-97ae-4c85-972a-1b4832af90da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c863cc0-d132-4d5c-9514-4ed2f2637a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba) (0.43.0)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ba4fff-46da-41bb-90f0-3d7baa46748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numba in c:\\programdata\\anaconda3\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba) (0.43.0)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "433fe7f2-04fd-4714-957b-b3374f68ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0      b'NVIDIA T400 4GB'                              [SUPPORTED]\n",
      "                      Compute Capability: 7.5\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-f748cbed-5ce7-bff1-bd01-ea1a21a5bf6f\n",
      "                                Watchdog: Enabled\n",
      "                            Compute Mode: WDDM\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.detect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c847f866-556b-465a-b94c-0731c894974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = \"pexels-magalie-parise-2147945619-32654307 (1).jpg\"\n",
    "img = Image.open(img_path).resize((224, 224)).convert(\"RGB\")\n",
    "img_np = np.array(img).astype(np.uint8)  # shape: (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "483d8421-076c-4234-a4b8-f8cafd5acf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nchw = img_np.transpose(2, 0, 1)  # shape: (3, 224, 224)\n",
    "\n",
    "# Get input quantization parameters from ONNX\n",
    "x_scale = get_array(\"data_scale\")      # should be float32 scalar\n",
    "x_zp = get_array(\"data_zero_point\")    # should be uint8 scalar\n",
    "\n",
    "# Quantize\n",
    "input_q = np.clip(np.round(img_nchw / x_scale) + x_zp, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8698a91-8de7-44a1-8bb1-0f4488c8fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Weights: (64, 3, 3, 3)\n",
      "Layer 2 Weights: (64, 64, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# === Load the model ===\n",
    "model_path = \"vgg16_int8.onnx\"\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "# === Get initializers ===\n",
    "initializer_map = {init.name: init for init in onnx_model.graph.initializer}\n",
    "def get_array(name): return numpy_helper.to_array(initializer_map[name])\n",
    "\n",
    "# === Extract QLinearConv nodes ===\n",
    "qconv_nodes = [node for node in onnx_model.graph.node if node.op_type == \"QLinearConv\"]\n",
    "layer_info = []\n",
    "\n",
    "for i, node in enumerate(qconv_nodes[:2]):\n",
    "    inputs = node.input[:8]  # First 8 inputs\n",
    "    x_scale = get_array(inputs[1])\n",
    "    x_zp = get_array(inputs[2])\n",
    "    W = get_array(inputs[3])\n",
    "    w_scale = get_array(inputs[4])\n",
    "    w_zp = get_array(inputs[5])\n",
    "    y_scale = get_array(inputs[6])\n",
    "    y_zp = get_array(inputs[7])\n",
    "    bias = get_array(node.input[8]) if len(node.input) > 8 else None\n",
    "    layer_info.append({\n",
    "        \"W\": W,\n",
    "        \"w_scale\": w_scale,\n",
    "        \"w_zp\": w_zp,\n",
    "        \"x_scale\": x_scale,\n",
    "        \"x_zp\": x_zp,\n",
    "        \"y_scale\": y_scale,\n",
    "        \"y_zp\": y_zp,\n",
    "        \"bias\": bias\n",
    "    })\n",
    "\n",
    "# Print shape confirmation\n",
    "print(\"Layer 1 Weights:\", layer_info[0]['W'].shape)\n",
    "print(\"Layer 2 Weights:\", layer_info[1]['W'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee05a069-45b7-44b3-9be5-a67f357cf733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = \"pexels-magalie-parise-2147945619-32654307 (1).jpg\"\n",
    "img = Image.open(img_path).resize((224, 224)).convert(\"RGB\")\n",
    "img_np = np.array(img).astype(np.uint8)  # shape: (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27ab8632-7db5-43a1-a3e7-926901ead060",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nchw = img_np.transpose(2, 0, 1)  # shape: (3, 224, 224)\n",
    "\n",
    "# Get input quantization parameters from ONNX\n",
    "x_scale = get_array(\"data_scale\")      # should be float32 scalar\n",
    "x_zp = get_array(\"data_zero_point\")    # should be uint8 scalar\n",
    "\n",
    "# Quantize\n",
    "input_q = np.clip(np.round(img_nchw / x_scale) + x_zp, 0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdc29eaf-1cb5-4672-b17d-b0aa84b1f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_qconv2d(input_q, W_q, bias, x_scale, x_zp, w_scale, w_zp, y_scale, y_zp, padding=1):\n",
    "    C_in, H, W = input_q.shape\n",
    "    C_out, _, kH, kW = W_q.shape\n",
    "\n",
    "    # Apply zero padding to the input\n",
    "    input_padded = np.pad(input_q, ((0, 0), (padding, padding), (padding, padding)), mode='constant', constant_values=x_zp)\n",
    "\n",
    "    # Output shape: HxW preserved\n",
    "    output = np.zeros((C_out, H, W), dtype=np.int32)\n",
    "\n",
    "    for oc in range(C_out):\n",
    "        acc = np.zeros((H, W), dtype=np.int32)\n",
    "        for ic in range(C_in):\n",
    "            for i in range(kH):\n",
    "                for j in range(kW):\n",
    "                    acc += (\n",
    "                        (input_padded[ic, i:i+H, j:j+W].astype(np.int32) - x_zp)\n",
    "                        * (W_q[oc, ic, i, j].astype(np.int32) - w_zp[oc])\n",
    "                    )\n",
    "        if bias is not None:\n",
    "            acc += int(np.round(bias[oc] / (x_scale * w_scale[oc])))\n",
    "\n",
    "        out_q = np.round(acc * x_scale * w_scale[oc] / y_scale + y_zp).astype(np.uint8)\n",
    "        output[oc] = np.clip(out_q, 0, 255)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc29b0b3-e433-40cb-ba07-94c7f02a9b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 1 Output Shape with padding: (64, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# === Run the full Layer 1 pass with padding ===\n",
    "layer1_out_q = manual_qconv2d(\n",
    "    input_q=input_q,\n",
    "    W_q=layer_info[0]['W'],\n",
    "    bias=layer_info[0]['bias'],\n",
    "    x_scale=layer_info[0]['x_scale'],\n",
    "    x_zp=layer_info[0]['x_zp'],\n",
    "    w_scale=layer_info[0]['w_scale'],\n",
    "    w_zp=layer_info[0]['w_zp'],\n",
    "    y_scale=layer_info[0]['y_scale'],\n",
    "    y_zp=layer_info[0]['y_zp'],\n",
    "    padding=1   # üëà Enables 224√ó224 output\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 1 Output Shape with padding:\", layer1_out_q.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03116593-8327-4dc2-aefd-05fce603cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(input_tensor, kernel_size=2, stride=2):\n",
    "    C, H, W = input_tensor.shape\n",
    "    out_H = (H - kernel_size) // stride + 1\n",
    "    out_W = (W - kernel_size) // stride + 1\n",
    "    pooled = np.zeros((C, out_H, out_W), dtype=input_tensor.dtype)\n",
    "    \n",
    "    for c in range(C):\n",
    "        for i in range(out_H):\n",
    "            for j in range(out_W):\n",
    "                h_start = i * stride\n",
    "                h_end = h_start + kernel_size\n",
    "                w_start = j * stride\n",
    "                w_end = w_start + kernel_size\n",
    "                pooled[c, i, j] = np.max(input_tensor[c, h_start:h_end, w_start:w_end])\n",
    "    \n",
    "    return pooled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ccfa233-713e-47d0-9b91-76351c0a2ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 2 Output Shape: (64, 224, 224)\n",
      "‚úÖ MaxPool Output Shape: (64, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "# === Run Layer 2 ===\n",
    "layer2_out_q = manual_qconv2d(\n",
    "    input_q=layer1_out_q,\n",
    "    W_q=layer_info[1]['W'],\n",
    "    bias=layer_info[1]['bias'],\n",
    "    x_scale=layer_info[1]['x_scale'],\n",
    "    x_zp=layer_info[1]['x_zp'],\n",
    "    w_scale=layer_info[1]['w_scale'],\n",
    "    w_zp=layer_info[1]['w_zp'],\n",
    "    y_scale=layer_info[1]['y_scale'],\n",
    "    y_zp=layer_info[1]['y_zp'],\n",
    "    padding=1  # üëà Padding to maintain 224x224\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 2 Output Shape:\", layer2_out_q.shape)  # Expect (64, 224, 224)\n",
    "\n",
    "# === Apply MaxPool ===\n",
    "layer2_pooled_q = maxpool2d(layer2_out_q, kernel_size=2, stride=2)\n",
    "print(\"‚úÖ MaxPool Output Shape:\", layer2_pooled_q.shape)  # Expect (64, 112, 112)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a10338b-3d33-4b39-aff2-40956c06627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W shape = (64, 3, 3, 3), bias shape = (64,)\n",
      "Layer 2: W shape = (64, 64, 3, 3), bias shape = (64,)\n",
      "Layer 3: W shape = (128, 64, 3, 3), bias shape = (128,)\n",
      "Layer 4: W shape = (128, 128, 3, 3), bias shape = (128,)\n",
      "Layer 5: W shape = (256, 128, 3, 3), bias shape = (256,)\n",
      "Layer 6: W shape = (256, 256, 3, 3), bias shape = (256,)\n",
      "Layer 7: W shape = (256, 256, 3, 3), bias shape = (256,)\n",
      "Layer 8: W shape = (512, 256, 3, 3), bias shape = (512,)\n",
      "Layer 9: W shape = (512, 512, 3, 3), bias shape = (512,)\n",
      "Layer 10: W shape = (512, 512, 3, 3), bias shape = (512,)\n",
      "Layer 11: W shape = (512, 512, 3, 3), bias shape = (512,)\n",
      "Layer 12: W shape = (512, 512, 3, 3), bias shape = (512,)\n",
      "Layer 13: W shape = (512, 512, 3, 3), bias shape = (512,)\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# Load the model\n",
    "model_path = \"vgg16_int8.onnx\"\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "# Build initializer map\n",
    "initializer_map = {init.name: init for init in onnx_model.graph.initializer}\n",
    "def get_array(name): return numpy_helper.to_array(initializer_map[name])\n",
    "\n",
    "# Extract all QLinearConv nodes\n",
    "qconv_nodes = [node for node in onnx_model.graph.node if node.op_type == \"QLinearConv\"]\n",
    "\n",
    "# Gather layer-wise data\n",
    "layer_info = []\n",
    "\n",
    "for i, node in enumerate(qconv_nodes):\n",
    "    inputs = node.input[:8]\n",
    "    layer_data = {\n",
    "        \"W\": get_array(inputs[3]),\n",
    "        \"w_scale\": get_array(inputs[4]),\n",
    "        \"w_zp\": get_array(inputs[5]),\n",
    "        \"x_scale\": get_array(inputs[1]),\n",
    "        \"x_zp\": get_array(inputs[2]),\n",
    "        \"y_scale\": get_array(inputs[6]),\n",
    "        \"y_zp\": get_array(inputs[7]),\n",
    "        \"bias\": get_array(node.input[8]) if len(node.input) > 8 else None\n",
    "    }\n",
    "    layer_info.append(layer_data)\n",
    "\n",
    "# Optional: print weight shapes to confirm\n",
    "for i, layer in enumerate(layer_info):\n",
    "    print(f\"Layer {i+1}: W shape = {layer['W'].shape}, bias shape = {None if layer['bias'] is None else layer['bias'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6fb5b3fd-8597-47cd-8776-4af72d28f0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 3 Output Shape: (128, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 3 Convolution ===\n",
    "layer3_out_q = manual_qconv2d(\n",
    "    input_q=layer2_pooled_q,                      # (64, 112, 112)\n",
    "    W_q=layer_info[2]['W'],                       # (128, 64, 3, 3)\n",
    "    bias=layer_info[2]['bias'],                   # (128,)\n",
    "    x_scale=layer_info[2]['x_scale'].item(),      # scalar\n",
    "    x_zp=layer_info[2]['x_zp'].item(),            # scalar\n",
    "    w_scale=layer_info[2]['w_scale'],             # (128,)\n",
    "    w_zp=layer_info[2]['w_zp'],                   # (128,)\n",
    "    y_scale=layer_info[2]['y_scale'].item(),      # scalar\n",
    "    y_zp=layer_info[2]['y_zp'].item(),            # scalar\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 3 Output Shape:\", layer3_out_q.shape)  # Should be (128, 112, 112)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55ba0e6a-04f1-4345-b626-11043b339e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 4 Output Shape: (128, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 4 Convolution ===\n",
    "layer4_out_q = manual_qconv2d(\n",
    "    input_q=layer3_out_q,                        # (128, 112, 112)\n",
    "    W_q=layer_info[3]['W'],                      # (128, 128, 3, 3)\n",
    "    bias=layer_info[3]['bias'],                  # (128,)\n",
    "    x_scale=layer_info[3]['x_scale'].item(),     # scalar\n",
    "    x_zp=layer_info[3]['x_zp'].item(),           # scalar\n",
    "    w_scale=layer_info[3]['w_scale'],            # (128,)\n",
    "    w_zp=layer_info[3]['w_zp'],                  # (128,)\n",
    "    y_scale=layer_info[3]['y_scale'].item(),     # scalar\n",
    "    y_zp=layer_info[3]['y_zp'].item(),           # scalar\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 4 Output Shape:\", layer4_out_q.shape)  # Expect (128, 112, 112)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b94af188-49ab-442d-8bf1-8c8b01db8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MaxPool Output Shape after Layer 4: (128, 56, 56)\n"
     ]
    }
   ],
   "source": [
    "# === MaxPool after Layer 4 ===\n",
    "layer4_pooled_q = maxpool2d(layer4_out_q, kernel_size=2, stride=2)\n",
    "print(\"‚úÖ MaxPool Output Shape after Layer 4:\", layer4_pooled_q.shape)  # Expect (128, 56, 56)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed820637-15ba-4185-ae0f-63949c2a119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 5 Output Shape: (256, 56, 56)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 5 (Conv after maxpool) ===\n",
    "layer5_out_q = manual_qconv2d(\n",
    "    input_q=layer4_pooled_q,\n",
    "    W_q=layer_info[4]['W'],\n",
    "    bias=layer_info[4]['bias'],\n",
    "    x_scale=layer_info[4]['x_scale'],\n",
    "    x_zp=layer_info[4]['x_zp'],\n",
    "    w_scale=layer_info[4]['w_scale'],\n",
    "    w_zp=layer_info[4]['w_zp'],\n",
    "    y_scale=layer_info[4]['y_scale'],\n",
    "    y_zp=layer_info[4]['y_zp'],\n",
    "    padding=1  # üëà To maintain 56x56\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 5 Output Shape:\", layer5_out_q.shape)  # Expect (256, 56, 56)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c66aaa61-0bae-4192-9361-cb3fdd0d39d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 6 Output Shape: (256, 56, 56)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 6 (Conv) ===\n",
    "layer6_out_q = manual_qconv2d(\n",
    "    input_q=layer5_out_q,\n",
    "    W_q=layer_info[5]['W'],\n",
    "    bias=layer_info[5]['bias'],\n",
    "    x_scale=layer_info[5]['x_scale'],\n",
    "    x_zp=layer_info[5]['x_zp'],\n",
    "    w_scale=layer_info[5]['w_scale'],\n",
    "    w_zp=layer_info[5]['w_zp'],\n",
    "    y_scale=layer_info[5]['y_scale'],\n",
    "    y_zp=layer_info[5]['y_zp'],\n",
    "    padding=1  # To preserve spatial size (56√ó56)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 6 Output Shape:\", layer6_out_q.shape)  # Expect (256, 56, 56)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a752c51-1458-44db-a959-7a29d1903bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 7 Output Shape: (256, 56, 56)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 7 (Conv) ===\n",
    "layer7_out_q = manual_qconv2d(\n",
    "    input_q=layer6_out_q,\n",
    "    W_q=layer_info[6]['W'],\n",
    "    bias=layer_info[6]['bias'],\n",
    "    x_scale=layer_info[6]['x_scale'],\n",
    "    x_zp=layer_info[6]['x_zp'],\n",
    "    w_scale=layer_info[6]['w_scale'],\n",
    "    w_zp=layer_info[6]['w_zp'],\n",
    "    y_scale=layer_info[6]['y_scale'],\n",
    "    y_zp=layer_info[6]['y_zp'],\n",
    "    padding=1  # Maintain shape (56x56)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 7 Output Shape:\", layer7_out_q.shape)  # Expect (256, 56, 56)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee0bd38d-b170-484c-b383-607b4c340067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MaxPool Output Shape: (256, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# === MaxPool after Layer 7 ===\n",
    "layer7_pooled_q = maxpool2d(layer7_out_q, kernel_size=2, stride=2)\n",
    "print(\"‚úÖ MaxPool Output Shape:\", layer7_pooled_q.shape)  # Expect (256, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "794a99db-69f2-4a90-b84a-10540dab2eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 8 Output Shape: (512, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 8 (Conv) ===\n",
    "layer8_out_q = manual_qconv2d(\n",
    "    input_q=layer7_pooled_q,\n",
    "    W_q=layer_info[7]['W'],\n",
    "    bias=layer_info[7]['bias'],\n",
    "    x_scale=layer_info[7]['x_scale'],\n",
    "    x_zp=layer_info[7]['x_zp'],\n",
    "    w_scale=layer_info[7]['w_scale'],\n",
    "    w_zp=layer_info[7]['w_zp'],\n",
    "    y_scale=layer_info[7]['y_scale'],\n",
    "    y_zp=layer_info[7]['y_zp'],\n",
    "    padding=1  # Maintain (28, 28)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 8 Output Shape:\", layer8_out_q.shape)  # Expect (512, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ded565dc-0f08-4ed2-b5ae-8eaf914443cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 9 Output Shape: (512, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 9 (Conv) ===\n",
    "layer9_out_q = manual_qconv2d(\n",
    "    input_q=layer8_out_q,\n",
    "    W_q=layer_info[8]['W'],\n",
    "    bias=layer_info[8]['bias'],\n",
    "    x_scale=layer_info[8]['x_scale'],\n",
    "    x_zp=layer_info[8]['x_zp'],\n",
    "    w_scale=layer_info[8]['w_scale'],\n",
    "    w_zp=layer_info[8]['w_zp'],\n",
    "    y_scale=layer_info[8]['y_scale'],\n",
    "    y_zp=layer_info[8]['y_zp'],\n",
    "    padding=1  # Keep output size same (28x28)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 9 Output Shape:\", layer9_out_q.shape)  # Expect (512, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a4771e4c-62ee-42a8-9c07-79f7cf94a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 10 Output Shape: (512, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 10 (Conv) ===\n",
    "layer10_out_q = manual_qconv2d(\n",
    "    input_q=layer9_out_q,\n",
    "    W_q=layer_info[9]['W'],\n",
    "    bias=layer_info[9]['bias'],\n",
    "    x_scale=layer_info[9]['x_scale'],\n",
    "    x_zp=layer_info[9]['x_zp'],\n",
    "    w_scale=layer_info[9]['w_scale'],\n",
    "    w_zp=layer_info[9]['w_zp'],\n",
    "    y_scale=layer_info[9]['y_scale'],\n",
    "    y_zp=layer_info[9]['y_zp'],\n",
    "    padding=1  # Keep output size same (28x28)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 10 Output Shape:\", layer10_out_q.shape)  # Expect (512, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9c0d495-e903-487f-9703-d9bb17f40e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MaxPool Output Shape after Layer 10: (512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# === MaxPool after Layer 10 ===\n",
    "layer10_pooled_q = maxpool2d(layer10_out_q, kernel_size=2, stride=2)\n",
    "\n",
    "print(\"‚úÖ MaxPool Output Shape after Layer 10:\", layer10_pooled_q.shape)  # Expect (512, 14, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fd6f66af-8c9e-4fcb-84b0-34dc4230eaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 11 Output Shape: (512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 11 ===\n",
    "layer11_out_q = manual_qconv2d(\n",
    "    input_q=layer10_pooled_q,\n",
    "    W_q=layer_info[10]['W'],\n",
    "    bias=layer_info[10]['bias'],\n",
    "    x_scale=layer_info[10]['x_scale'],\n",
    "    x_zp=layer_info[10]['x_zp'],\n",
    "    w_scale=layer_info[10]['w_scale'],\n",
    "    w_zp=layer_info[10]['w_zp'],\n",
    "    y_scale=layer_info[10]['y_scale'],\n",
    "    y_zp=layer_info[10]['y_zp'],\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 11 Output Shape:\", layer11_out_q.shape)  # Expected: (512, 14, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "44afcf84-03ad-4416-a378-f0cb268214ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 12 Output Shape: (512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 12 (Conv) ===\n",
    "layer12_out_q = manual_qconv2d(\n",
    "    input_q=layer11_out_q,\n",
    "    W_q=layer_info[11]['W'],\n",
    "    bias=layer_info[11]['bias'],\n",
    "    x_scale=layer_info[11]['x_scale'],\n",
    "    x_zp=layer_info[11]['x_zp'],\n",
    "    w_scale=layer_info[11]['w_scale'],\n",
    "    w_zp=layer_info[11]['w_zp'],\n",
    "    y_scale=layer_info[11]['y_scale'],\n",
    "    y_zp=layer_info[11]['y_zp'],\n",
    "    padding=1  # Maintain (14, 14)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 12 Output Shape:\", layer12_out_q.shape)  # Expect (512, 14, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4b7fd84e-062f-4872-8db8-fa0f315abfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Layer 13 Output Shape: (512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# === Layer 13 (Conv) ===\n",
    "layer13_out_q = manual_qconv2d(\n",
    "    input_q=layer12_out_q,\n",
    "    W_q=layer_info[12]['W'],\n",
    "    bias=layer_info[12]['bias'],\n",
    "    x_scale=layer_info[12]['x_scale'],\n",
    "    x_zp=layer_info[12]['x_zp'],\n",
    "    w_scale=layer_info[12]['w_scale'],\n",
    "    w_zp=layer_info[12]['w_zp'],\n",
    "    y_scale=layer_info[12]['y_scale'],\n",
    "    y_zp=layer_info[12]['y_zp'],\n",
    "    padding=1  # Keep output size at 14x14\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Layer 13 Output Shape:\", layer13_out_q.shape)  # Expect (512, 14, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7be353f4-ff82-4a49-8e84-66c2c14192e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MaxPool Output Shape after Layer 13: (512, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# === MaxPool after Layer 13 ===\n",
    "layer13_pooled_q = maxpool2d(layer13_out_q, kernel_size=2, stride=2)\n",
    "\n",
    "print(\"‚úÖ MaxPool Output Shape after Layer 13:\", layer13_pooled_q.shape)  # Expect (512, 7, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4ff3b886-2a09-41e4-b8f0-33255268823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dequantized Flattened Output Shape: (25088,)\n"
     ]
    }
   ],
   "source": [
    "# === Flatten pooled output ===\n",
    "flattened_q = layer13_pooled_q.flatten()  # Shape: (512 * 7 * 7 = 25088,)\n",
    "\n",
    "# === Dequantize before FC ===\n",
    "x_scale_fc = 0.27242821\n",
    "x_zp_fc = 0\n",
    "\n",
    "flattened_f32 = x_scale_fc * (flattened_q.astype(np.float32) - x_zp_fc)\n",
    "\n",
    "print(\"‚úÖ Dequantized Flattened Output Shape:\", flattened_f32.shape)  # (25088,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a0e340f-ce12-4916-9917-3ed018218432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Initializers:\n",
      "data_zero_point ()\n",
      "data_scale ()\n",
      "vgg0_conv0_weight_quantized (64, 3, 3, 3)\n",
      "vgg0_conv0_weight_scale (64,)\n",
      "vgg0_conv0_weight_zero_point (64,)\n",
      "vgg0_conv0_bias_quantized (64,)\n",
      "vgg0_conv0_fwd_zero_point ()\n",
      "vgg0_conv0_fwd_scale ()\n",
      "vgg0_conv1_weight_quantized (64, 64, 3, 3)\n",
      "vgg0_conv1_weight_scale (64,)\n",
      "vgg0_conv1_weight_zero_point (64,)\n",
      "vgg0_conv1_bias_quantized (64,)\n",
      "vgg0_conv1_fwd_zero_point ()\n",
      "vgg0_conv1_fwd_scale ()\n",
      "vgg0_conv2_weight_quantized (128, 64, 3, 3)\n",
      "vgg0_conv2_weight_scale (128,)\n",
      "vgg0_conv2_weight_zero_point (128,)\n",
      "vgg0_conv2_bias_quantized (128,)\n",
      "vgg0_conv2_fwd_zero_point ()\n",
      "vgg0_conv2_fwd_scale ()\n",
      "vgg0_conv3_weight_quantized (128, 128, 3, 3)\n",
      "vgg0_conv3_weight_scale (128,)\n",
      "vgg0_conv3_weight_zero_point (128,)\n",
      "vgg0_conv3_bias_quantized (128,)\n",
      "vgg0_conv3_fwd_zero_point ()\n",
      "vgg0_conv3_fwd_scale ()\n",
      "vgg0_conv4_weight_quantized (256, 128, 3, 3)\n",
      "vgg0_conv4_weight_scale (256,)\n",
      "vgg0_conv4_weight_zero_point (256,)\n",
      "vgg0_conv4_bias_quantized (256,)\n",
      "vgg0_conv4_fwd_zero_point ()\n",
      "vgg0_conv4_fwd_scale ()\n",
      "vgg0_conv5_weight_quantized (256, 256, 3, 3)\n",
      "vgg0_conv5_weight_scale (256,)\n",
      "vgg0_conv5_weight_zero_point (256,)\n",
      "vgg0_conv5_bias_quantized (256,)\n",
      "vgg0_conv5_fwd_zero_point ()\n",
      "vgg0_conv5_fwd_scale ()\n",
      "vgg0_conv6_weight_quantized (256, 256, 3, 3)\n",
      "vgg0_conv6_weight_scale (256,)\n",
      "vgg0_conv6_weight_zero_point (256,)\n",
      "vgg0_conv6_bias_quantized (256,)\n",
      "vgg0_conv6_fwd_zero_point ()\n",
      "vgg0_conv6_fwd_scale ()\n",
      "vgg0_conv7_weight_quantized (512, 256, 3, 3)\n",
      "vgg0_conv7_weight_scale (512,)\n",
      "vgg0_conv7_weight_zero_point (512,)\n",
      "vgg0_conv7_bias_quantized (512,)\n",
      "vgg0_conv7_fwd_zero_point ()\n",
      "vgg0_conv7_fwd_scale ()\n",
      "vgg0_conv8_weight_quantized (512, 512, 3, 3)\n",
      "vgg0_conv8_weight_scale (512,)\n",
      "vgg0_conv8_weight_zero_point (512,)\n",
      "vgg0_conv8_bias_quantized (512,)\n",
      "vgg0_conv8_fwd_zero_point ()\n",
      "vgg0_conv8_fwd_scale ()\n",
      "vgg0_conv9_weight_quantized (512, 512, 3, 3)\n",
      "vgg0_conv9_weight_scale (512,)\n",
      "vgg0_conv9_weight_zero_point (512,)\n",
      "vgg0_conv9_bias_quantized (512,)\n",
      "vgg0_conv9_fwd_zero_point ()\n",
      "vgg0_conv9_fwd_scale ()\n",
      "vgg0_conv10_weight_quantized (512, 512, 3, 3)\n",
      "vgg0_conv10_weight_scale (512,)\n",
      "vgg0_conv10_weight_zero_point (512,)\n",
      "vgg0_conv10_bias_quantized (512,)\n",
      "vgg0_conv10_fwd_zero_point ()\n",
      "vgg0_conv10_fwd_scale ()\n",
      "vgg0_conv11_weight_quantized (512, 512, 3, 3)\n",
      "vgg0_conv11_weight_scale (512,)\n",
      "vgg0_conv11_weight_zero_point (512,)\n",
      "vgg0_conv11_bias_quantized (512,)\n",
      "vgg0_conv11_fwd_zero_point ()\n",
      "vgg0_conv11_fwd_scale ()\n",
      "vgg0_conv12_weight_quantized (512, 512, 3, 3)\n",
      "vgg0_conv12_weight_scale (512,)\n",
      "vgg0_conv12_weight_zero_point (512,)\n",
      "vgg0_conv12_bias_quantized (512,)\n",
      "vgg0_conv12_fwd_zero_point ()\n",
      "vgg0_conv12_fwd_scale ()\n",
      "flatten_60_zero_point ()\n",
      "flatten_60_scale ()\n",
      "vgg0_dense0_weight_quantized (25088, 4096)\n",
      "vgg0_dense0_weight_scale ()\n",
      "vgg0_dense0_weight_zero_point ()\n",
      "vgg0_dense0_fwd_MatMul_zero_point ()\n",
      "vgg0_dense0_fwd_MatMul_scale ()\n",
      "vgg0_dense0_fwd_zero_point ()\n",
      "vgg0_dense0_fwd_scale ()\n",
      "vgg0_dense0_bias_quantized (4096,)\n",
      "vgg0_dense0_bias_scale ()\n",
      "vgg0_dense0_bias_zero_point ()\n",
      "flatten_65_zero_point ()\n",
      "flatten_65_scale ()\n",
      "vgg0_dense1_weight_quantized (4096, 4096)\n",
      "vgg0_dense1_weight_scale ()\n",
      "vgg0_dense1_weight_zero_point ()\n",
      "vgg0_dense1_fwd_MatMul_zero_point ()\n",
      "vgg0_dense1_fwd_MatMul_scale ()\n",
      "vgg0_dense1_fwd_zero_point ()\n",
      "vgg0_dense1_fwd_scale ()\n",
      "vgg0_dense1_bias_quantized (4096,)\n",
      "vgg0_dense1_bias_scale ()\n",
      "vgg0_dense1_bias_zero_point ()\n",
      "flatten_70_zero_point ()\n",
      "flatten_70_scale ()\n",
      "vgg0_dense2_weight_quantized (4096, 1000)\n",
      "vgg0_dense2_weight_scale ()\n",
      "vgg0_dense2_weight_zero_point ()\n",
      "vgg0_dense2_fwd_MatMul_zero_point ()\n",
      "vgg0_dense2_fwd_MatMul_scale ()\n",
      "vgg0_dense2_fwd_zero_point ()\n",
      "vgg0_dense2_fwd_scale ()\n",
      "vgg0_dense2_bias_quantized (1000,)\n",
      "vgg0_dense2_bias_scale ()\n",
      "vgg0_dense2_bias_zero_point ()\n",
      "‚ö†Ô∏è Missing: 'fc.weight1'\n",
      "‚ö†Ô∏è Missing: 'fc.weight2'\n",
      "‚ö†Ô∏è Missing: 'fc.weight3'\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# Load model\n",
    "model_path = \"vgg16_int8.onnx\"\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "# Build initializer map\n",
    "initializer_map = {init.name: init for init in onnx_model.graph.initializer}\n",
    "def get_array(name): return numpy_helper.to_array(initializer_map[name])\n",
    "\n",
    "# List all initializers (to locate FC layers)\n",
    "print(\"All Initializers:\")\n",
    "for name in initializer_map:\n",
    "    print(name, get_array(name).shape)\n",
    "\n",
    "# === Extract FC Weights and Biases ===\n",
    "\n",
    "# These are likely the FC layers; replace names if needed based on the above printout\n",
    "fc_names = {\n",
    "    \"fc1\": {\n",
    "        \"W\": \"fc.weight1\",   # likely: (25088, 4096)\n",
    "        \"B\": \"fc.bias1\"\n",
    "    },\n",
    "    \"fc2\": {\n",
    "        \"W\": \"fc.weight2\",   # likely: (4096, 4096)\n",
    "        \"B\": \"fc.bias2\"\n",
    "    },\n",
    "    \"fc3\": {\n",
    "        \"W\": \"fc.weight3\",   # likely: (4096, 1000)\n",
    "        \"B\": \"fc.bias3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "fc_weights = {}\n",
    "for fc, names in fc_names.items():\n",
    "    try:\n",
    "        W = get_array(names[\"W\"])\n",
    "        B = get_array(names[\"B\"])\n",
    "        fc_weights[fc] = {\"W\": W, \"B\": B}\n",
    "        print(f\"{fc.upper()} -> W: {W.shape}, B: {B.shape}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"‚ö†Ô∏è Missing: {e}\")\n",
    "\n",
    "# Now `fc_weights['fc1']['W']` gives FC1 weights, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b319a909-2fba-4191-990a-e12fbe725d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ FC Layer 1\n",
      "  Weight shape: (25088, 4096)\n",
      "  Bias shape: (4096,)\n",
      "  Weight scale: 0.0003788646135944873\n",
      "  Bias scale: 0.0008186898776330054\n",
      "  Output scale (MatMul): 0.2407444268465042\n",
      "  Final output scale (post-add): 0.09747663140296936\n",
      "\n",
      "üîπ FC Layer 2\n",
      "  Weight shape: (4096, 4096)\n",
      "  Bias shape: (4096,)\n",
      "  Weight scale: 0.0004914611927233636\n",
      "  Bias scale: 0.0006801208946853876\n",
      "  Output scale (MatMul): 0.15741786360740662\n",
      "  Final output scale (post-add): 0.05860837176442146\n",
      "\n",
      "üîπ FC Layer 3\n",
      "  Weight shape: (4096, 1000)\n",
      "  Bias shape: (1000,)\n",
      "  Weight scale: 0.0010433332063257694\n",
      "  Bias scale: 0.0007945160032249987\n",
      "  Output scale (MatMul): 0.2589195668697357\n",
      "  Final output scale (post-add): 0.25890347361564636\n"
     ]
    }
   ],
   "source": [
    "fc_layer_info = []\n",
    "\n",
    "fc_names = [\"dense0\", \"dense1\", \"dense2\"]\n",
    "\n",
    "for i, fc in enumerate(fc_names):\n",
    "    layer = {}\n",
    "    prefix = f\"vgg0_{fc}_\"\n",
    "\n",
    "    # Weight and bias\n",
    "    layer[\"W\"] = get_array(prefix + \"weight_quantized\")          # int8 weights\n",
    "    layer[\"w_scale\"] = get_array(prefix + \"weight_scale\")        # float32\n",
    "    layer[\"w_zp\"] = get_array(prefix + \"weight_zero_point\")      # int8 or uint8\n",
    "    \n",
    "    layer[\"bias\"] = get_array(prefix + \"bias_quantized\")         # int8 bias\n",
    "    layer[\"bias_scale\"] = get_array(prefix + \"bias_scale\")\n",
    "    layer[\"bias_zp\"] = get_array(prefix + \"bias_zero_point\")\n",
    "\n",
    "    # Output (MatMul) quant params\n",
    "    layer[\"out_scale\"] = get_array(prefix + \"fwd_MatMul_scale\")\n",
    "    layer[\"out_zp\"] = get_array(prefix + \"fwd_MatMul_zero_point\")\n",
    "\n",
    "    # Final output of layer (after add)\n",
    "    layer[\"y_scale\"] = get_array(prefix + \"fwd_scale\")\n",
    "    layer[\"y_zp\"] = get_array(prefix + \"fwd_zero_point\")\n",
    "\n",
    "    fc_layer_info.append(layer)\n",
    "\n",
    "# ‚úÖ Summary\n",
    "for i, layer in enumerate(fc_layer_info):\n",
    "    print(f\"\\nüîπ FC Layer {i+1}\")\n",
    "    print(f\"  Weight shape: {layer['W'].shape}\")\n",
    "    print(f\"  Bias shape: {layer['bias'].shape}\")\n",
    "    print(f\"  Weight scale: {layer['w_scale']}\")\n",
    "    print(f\"  Bias scale: {layer['bias_scale']}\")\n",
    "    print(f\"  Output scale (MatMul): {layer['out_scale']}\")\n",
    "    print(f\"  Final output scale (post-add): {layer['y_scale']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "717503b6-ac8c-4353-a481-e1e97b9d940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fc_layer(x_float, W_q, w_scale, w_zp, bias_q, bias_scale, bias_zp,\n",
    "                 input_scale, input_zp, out_scale_matmul, out_zp_matmul,\n",
    "                 out_scale_final, out_zp_final):\n",
    "    \"\"\"\n",
    "    x_float: float32 input vector\n",
    "    W_q: int8 weight matrix\n",
    "    bias_q: int8 bias vector\n",
    "    Returns final float32 output after quantized matmul + bias + dequant\n",
    "    \"\"\"\n",
    "    # Step 1: Quantize input\n",
    "    x_q = np.clip(np.round(x_float / input_scale) + input_zp, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Step 2: QLinearMatMul\n",
    "    x_int32 = x_q.astype(np.int32) - input_zp\n",
    "    W_int32 = W_q.astype(np.int32) - w_zp\n",
    "    out_int32 = np.dot(x_int32, W_int32)\n",
    "\n",
    "    # Step 3: Requantize to intermediate output (same as ONNX QLinearMatMul)\n",
    "    result_q = np.round(out_int32 * (input_scale * w_scale / out_scale_matmul) + out_zp_matmul).astype(np.uint8)\n",
    "\n",
    "    # Step 4: QLinearAdd (bias)\n",
    "    A = result_q.astype(np.int32) - out_zp_matmul\n",
    "    B = bias_q.astype(np.int32) - bias_zp\n",
    "    C_int32 = A + B  # In ONNX, both A and B are in same scale domain\n",
    "\n",
    "    # Step 5: Final quantization\n",
    "    final_q = np.round(C_int32 * (out_scale_matmul / out_scale_final) + out_zp_final)\n",
    "    final_q = np.clip(final_q, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Step 6: Dequantize\n",
    "    final_float = out_scale_final * (final_q.astype(np.float32) - out_zp_final)\n",
    "    return final_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6e363b17-64a9-4c04-9a5a-05351ec53ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final output logits shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# FC1 parameters\n",
    "W1 = fc_layer_info[0]['W']\n",
    "B1 = fc_layer_info[0]['bias']\n",
    "out1 = run_fc_layer(\n",
    "    x_float=flattened_f32,\n",
    "    W_q=W1, w_scale=0.0003788646, w_zp=0,\n",
    "    bias_q=B1, bias_scale=0.0008186898, bias_zp=128,\n",
    "    input_scale=0.27242821, input_zp=0,\n",
    "    out_scale_matmul=0.24074442, out_zp_matmul=152,\n",
    "    out_scale_final=0.09747663, out_zp_final=0\n",
    ")\n",
    "\n",
    "# FC2\n",
    "W2 = fc_layer_info[1]['W']\n",
    "B2 = fc_layer_info[1]['bias']\n",
    "out2 = run_fc_layer(\n",
    "    x_float=out1,\n",
    "    W_q=W2, w_scale=0.0004914612, w_zp=0,\n",
    "    bias_q=B2, bias_scale=0.0006801208, bias_zp=128,\n",
    "    input_scale=0.09747663, input_zp=0,\n",
    "    out_scale_matmul=0.15741786, out_zp_matmul=0,\n",
    "    out_scale_final=0.05860837, out_zp_final=0\n",
    ")\n",
    "\n",
    "# FC3\n",
    "W3 = fc_layer_info[2]['W']\n",
    "B3 = fc_layer_info[2]['bias']\n",
    "out3 = run_fc_layer(\n",
    "    x_float=out2,\n",
    "    W_q=W3, w_scale=0.0010433332, w_zp=0,\n",
    "    bias_q=B3, bias_scale=0.0007945160, bias_zp=128,\n",
    "    input_scale=0.05860837, input_zp=0,\n",
    "    out_scale_matmul=0.25891956, out_zp_matmul=0,\n",
    "    out_scale_final=0.25890347, out_zp_final=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Final output logits shape:\", out3.shape)  # Should be (1000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2acebbfd-4768-4754-a53d-909579fcf2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Top-1 Class Index: 21\n",
      "üîù Top-5 Class Indices: [333 876 474 664 965]\n",
      "üìä Top-5 Probabilities: [0.02323296 0.02323296 0.02323296 0.02323296 0.02323296]\n"
     ]
    }
   ],
   "source": [
    "def softmax(logits):\n",
    "    exps = np.exp(logits - np.max(logits))  # subtract max for numerical stability\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "# Apply softmax\n",
    "probs = softmax(out3)\n",
    "\n",
    "# Top-1 and Top-5 predictions\n",
    "top1 = np.argmax(probs)\n",
    "top5 = np.argsort(probs)[-5:][::-1]\n",
    "\n",
    "print(\"üîÆ Top-1 Class Index:\", top1)\n",
    "print(\"üîù Top-5 Class Indices:\", top5)\n",
    "print(\"üìä Top-5 Probabilities:\", probs[top5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e185f-ced4-42f5-8e9b-0f6183e4b9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b963442-84f5-4585-8dd7-093ac9fbff7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e719a4-4819-4e39-9cfd-f9ec5af82881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
